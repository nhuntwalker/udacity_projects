---
title: "Data_Analysis_ND_p4_nmhw"
author: Nicholas Hunt-Walker
output: html_document
---

Before we do anything, let's call the requisite libraries and go to the right working directory.
```{r}
library(ggplot2) # for making any plots
library(gridExtra) #for making multi-panel plots
library(GGally)
library(memisc) #for data analysis stuff
setwd("/Users/Nick/Documents/udacity/projects/project4/")
```


And now we load the data. Note that the column descriptions can be found [here](./Prosper Loan Data - Variable Definitions.xlsx)
```{r}
prosper <- read.csv("prosperLoanData.csv")
names(prosper)
```


Some things to know about the data set before moving forward:
- 113,937 observations, each with 81 (!!!!) variables
- Last updated 03/11/2014

---
## Resource Links
- http://stackoverflow.com/questions/1169248/r-function-for-testing-if-a-vector-contains-a-given-element
- https://stat.ethz.ch/R-manual/R-devel/library/base/html/strptime.html
- http://stackoverflow.com/questions/9852832/r-not-in-subset
- https://cran.r-project.org/web/packages/texreg/vignettes/v55i08.pdf
---

There are five columns that contain date information. These are:
- ListingCreationDate
- ClosedDate
- DateCreditPulled
- FirstRecordedCreditLine
- LoanOriginationDate

These may be useful for later, but as they stand right now they're not usable. Let's make them datetime objects. 

Write a function that takes in a dataframe and a column of choice, and adds columns to the dataframe that splits the datetime object. I want the year, the month (maybe cyclical?), the day, as well as the date as a decimal of the year.
```{r}
split_to_columns <- function(df, input_colnum, output_colname_assoc_arr) {
  dates <- strptime(df[, input_colnum], format="%Y-%m-%d %H:%M:%S")
  df[output_colname_assoc_arr["year"]] <- as.numeric(strftime(dates, format="%Y"))
  df[output_colname_assoc_arr["month"]] <- as.numeric(strftime(dates, format="%m"))
  df[output_colname_assoc_arr["day"]] <- as.numeric(strftime(dates, format="%d"))
  df[output_colname_assoc_arr["decimal_date"]] <- df[output_colname_assoc_arr["year"]] + (as.numeric(strftime(dates, format="%j"))/366)
  
  return(df)
}
```

```{r}
#column 3
listing_creation_date_set <- c()
listing_creation_date_set["year"] <- "ListingCreationDate_year"
listing_creation_date_set["month"] <- "ListingCreationDate_month"
listing_creation_date_set["day"] <- "ListingCreationDate_day"
listing_creation_date_set["decimal_date"] <- "ListingCreationDate_decimal"

#column 7
closed_date_set <- c()
closed_date_set["year"] <- "ClosedDate_year"
closed_date_set["month"] <- "ClosedDate_month"
closed_date_set["day"] <- "ClosedDate_day"
closed_date_set["decimal_date"] <- "ClosedDate_decimal"

#column 25
credit_pulled_set <- c()
credit_pulled_set["year"] <- "DateCreditPulled_year"
credit_pulled_set["month"] <- "DateCreditPulled_month"
credit_pulled_set["day"] <- "DateCreditPulled_day"
credit_pulled_set["decimal_date"] <- "DateCreditPulled_decimal"

#column 28
first_recorded_credit_set <- c()
first_recorded_credit_set["year"] <- "FirstRecordedCreditLine_year"
first_recorded_credit_set["month"] <- "FirstRecordedCreditLine_month"
first_recorded_credit_set["day"] <- "FirstRecordedCreditLine_day"
first_recorded_credit_set["decimal_date"] <- "FirstRecordedCreditLine_decimal"

#column 65
loan_orig_date_set <- c()
loan_orig_date_set["year"] <- "LoanOriginationDate_year"
loan_orig_date_set["month"] <- "LoanOriginationDate_month"
loan_orig_date_set["day"] <- "LoanOriginationDate_day"
loan_orig_date_set["decimal_date"] <- "LoanOriginationDate_decimal"

prosper <- split_to_columns(prosper, 3, listing_creation_date_set)
prosper <- split_to_columns(prosper, 7, closed_date_set)
prosper <- split_to_columns(prosper, 25, credit_pulled_set)
prosper <- split_to_columns(prosper, 28, first_recorded_credit_set)
prosper <- split_to_columns(prosper, 65, loan_orig_date_set)
```


First Plots: Histograms of potentially interesting things
```{r}
#Listing Creation Date split by term length
ggplot(data=subset(prosper, !is.na(Term)), aes(x=ListingCreationDate_decimal)) + 
  geom_histogram(binwidth=1/12) + 
  xlab("Listing Creation Date") +
  scale_x_continuous(breaks=seq(2005, 2015)) +
  facet_wrap(~Term, ncol = 1, scales="free_y")

#Borrower APR split by term length
ggplot(data=subset(prosper, !is.na(Term)), aes(x=BorrowerAPR)) +
  geom_histogram() +
  xlab("Borrower APR (%)") +
  facet_wrap(~Term, ncol = 1, scales="free_y")

ggplot(data=subset(prosper, !is.na(Term) & !is.na(ProsperRating..Alpha.)), aes(x=ProsperRating..Alpha.)) +
  geom_histogram() +
  xlab("Credit Rating") +
  facet_wrap(~Term, ncol = 1, scales="free_y")

ggplot(data=prosper, aes(x=ListingCategory..numeric.)) +
  geom_histogram(binwidth=1) +
  xlab("Listing Category")
```

Is the stated monthly income a continuous series of numbers or is it split into categories?
```{r}
summary(prosper$StatedMonthlyIncome)
```
Looks to be continuous to me. between 0 and $1.75 million. I should be able to make a histogram of that too. This is the stated monthly income *at the time of borrowing*
```{r}
ggplot(data=prosper, aes(x=StatedMonthlyIncome)) +
  geom_histogram(binwidth=1000) +
  xlim(0, 50000) +
  xlab("Stated Monthly Income ($)") +
  facet_wrap(~Term, ncol=1, scales="free_y")
```

What about the original loan amount?
```{r}
ggplot(data=prosper, aes(x=LoanOriginalAmount)) +
  geom_histogram() +
  xlab("Loan Principal ($)")
```
Hmm.... Is there some correlation between loan amount and stated monthly income?
```{r}
with(prosper, cor.test(LoanOriginalAmount, StatedMonthlyIncome))
```
Correlation coefficient = 0.2012595. Quite lower than what I was expecting. Let's see what the scatterplot says
```{r}
ggplot(data=subset(prosper, StatedMonthlyIncome < 10000), aes(y=LoanOriginalAmount, x=StatedMonthlyIncome)) +
  geom_point(position="jitter", alpha=0.2, aes(color=factor(Term))) +
  xlab("Stated Monthly Income ($)") +
  ylab("Loan Principal ($)") 
```

I wonder if there's any visible difference when coloring on Borrower APR instead of just term.
```{r}
ggplot(data=subset(prosper, (StatedMonthlyIncome < 10000) & (EmploymentStatus != "")),
       aes(y=LoanOriginalAmount, x=StatedMonthlyIncome)) +
  geom_point(position="jitter", alpha=0.2, aes(color=factor(EmploymentStatus))) +
  xlab("Stated Monthly Income ($)") +
  ylab("Loan Principal ($)") 
```

Somewhat. Smaller loans for those employed part time. A ton of borrowers are employed or self-employed though. Let's see the employment statuses of borrowers more explicitly.
```{r}
ggplot(data=subset(prosper, (EmploymentStatus != "") & (EmploymentStatus != "Not available")), aes(x=EmploymentStatus)) +
  geom_bar() +
  xlab("Employment Status") +
  scale_y_log10()
```

This could be an interesting thing to look at. Is there a split on Term?
```{r}
ggplot(data=subset(prosper, (EmploymentStatus != "") & (EmploymentStatus != "Not available")), aes(x=EmploymentStatus)) +
  geom_bar(aes(fill=factor(Term))) +
  xlab("Employment Status") +
  scale_y_log10()
```
Oooh this is money right here. 

Here's another question then, is there a significant difference between the ways different employment statuses borrow over time?
```{r}
ggplot(data=subset(prosper, !is.na(LoanOriginalAmount) & (EmploymentStatus != "")), aes(x=ListingCreationDate_decimal, y=LoanOriginalAmount)) + 
  geom_point(aes(color=factor(EmploymentStatus)), alpha=0.1, position="jitter") + 
  xlab("Listing Creation Date") +
  scale_x_continuous(breaks=seq(2005, 2015)) +
  scale_y_sqrt()
```

The employed and full-time borrowers wash out everyone else, so let's see what it looks like without them.
```{r}
ggplot(data=subset(prosper, !is.na(LoanOriginalAmount) & (EmploymentStatus != "") & (EmploymentStatus != "Not available") & (EmploymentStatus != "Employed") & (EmploymentStatus != "Full-time")), aes(x=ListingCreationDate_decimal, y=LoanOriginalAmount)) + 
  geom_point(aes(color=factor(EmploymentStatus)), alpha=0.2, position="jitter") + 
  xlab("Listing Creation Date") +
  scale_x_continuous(breaks=seq(2005, 2015))
```


Onto other things. There's a variable for the percent of the listing funded. I suspect there may be a correlation between the PercentFunded and the amount asked for.
```{r}
with(prosper, cor.test(LoanOriginalAmount, PercentFunded))
```
-0.01024815 is basically no correlation at all. Disappointment. 

Let's see what that PercentFunded parameter looks like
```{r}
ggplot(data=subset(prosper, !is.na(PercentFunded)), aes(x=PercentFunded)) +
  geom_histogram(binwidth=0.1, origin=-0.05) +
  xlim(0.6, 1.1)

ggplot(data=subset(prosper, !is.na(PercentFunded)), aes(x=PercentFunded)) +
  geom_histogram(binwidth=0.1, origin=-0.05) +
  xlim(0.6, 1.1) + scale_y_log10()
```
Oh that's why. Because the vaaaaast majority of loans are fully funded. That was useless and enlightening all at once. 

Let's quantify just how many are fully funded
```{r}
sum(with(prosper, (PercentFunded == 1.0) & !is.na(PercentFunded))) / sum(with(prosper, !is.na(PercentFunded))) * 100
```
99.236%! Yeah, we're not going to get any meaningful correlations out of this one.

Another column is LP_NetPrincipalLoss. It's the principal that remains uncollected after any recoveries. Curious to see if there's any relationship between that and the loan amount. Of course, we start with the cor.test function, then plot some stuff up to see the distribution.
```{r}
with(prosper, cor.test(LP_NetPrincipalLoss, LoanOriginalAmount))
```
A correlation coefficient of 0.1274. Not the worst I've seen thus far, but still not great. Let's see the plot
```{r}
ggplot(data=subset(prosper, !is.na(LP_NetPrincipalLoss)), aes(x=LoanOriginalAmount, y = LP_NetPrincipalLoss)) + geom_point(alpha=0.2, position="jitter") +
  xlab("Loan Principal ($)") +
  ylab("Net Principal Loss ($)")
```
Ok now this is actually somewhat interesting. It seems that when there is a non-zero loss, there might actually be some correlation. Let's test that again with cor.test
```{r}
with(subset(prosper, LP_NetPrincipalLoss > 0), cor.test(LP_NetPrincipalLoss, LoanOriginalAmount))
```
WHOA! 0.8895%! That is a very strong positive correlation between loss on the principal and the principal loan amount. Plot says...! (with a linear model overplotted, as well as a 1-1 line for reference)
```{r}
ggplot(data=subset(prosper, LP_NetPrincipalLoss > 0), aes(x=LoanOriginalAmount, y = LP_NetPrincipalLoss)) + geom_point(alpha=0.2, position="jitter") +
  xlab("Loan Principal ($)") +
  ylab("Net Principal Loss ($)") +
  stat_smooth(method='lm') +
  geom_abline(intercept=0, slope=1, color="red", linetype=2)
```
Now that's interesting. It seems that in many cases, especially for the smaller loans, when there's a loss it's on most of the loan if not all of the loan. 

Let's plot the median Net Principal Loss vs Loan Principal here. For clarity, we should probably bin up the loan principal.
```{r}
loss_bin = 500
ggplot(data=subset(prosper, LP_NetPrincipalLoss > 0), aes(x=round(LoanOriginalAmount / loss_bin) * loss_bin, y = LP_NetPrincipalLoss)) + geom_point(alpha=0.2, position="jitter") +
  xlab("Loan Principal ($)") +
  ylab("Net Principal Loss ($)") +
  geom_line(stat="summary", color="red", fun.y = median, size=1)
```
Ther's another dimension to this that I'm not looking at. 

Does Income Range have an effect on how much of the loan is lost?
```{r}
loss_bin = 500
ggplot(data=subset(prosper, (LP_NetPrincipalLoss > 0) & (IncomeRange != "Not displayed") & (IncomeRange != "Not employed") & (IncomeRange != "$0")), aes(x=round(LoanOriginalAmount / loss_bin) * loss_bin, y = LP_NetPrincipalLoss)) + geom_point(alpha=0.5, position="jitter", aes(color=factor(IncomeRange))) +
  xlab("Loan Principal ($)") +
  ylab("Net Principal Loss ($)") +
  geom_line(stat="summary", color="red", fun.y = median, size=1)
```
No real effect here. Most of these losses are coming in for the $25 - 75k range. 

What about the rating of the loan? For reference, AA is the lowest risk loan, and HR is highest-risk.
```{r}
loss_bin = 500
ggplot(data=subset(prosper, (LP_NetPrincipalLoss > 0) & (ProsperRating..Alpha. != "")), aes(x=round(LoanOriginalAmount / loss_bin) * loss_bin, y = LP_NetPrincipalLoss)) + geom_point(alpha=0.5, position="jitter", aes(color=factor(ProsperRating..Alpha.))) +
  xlab("Loan Principal ($)") +
  ylab("Net Principal Loss ($)") +
  geom_line(stat="summary", color="red", fun.y = median, size=1)
```
Interestingly enough, the highest-risk loans aren't dominating this landscape of loan principal loss. At the low end? Sure there's a bunch. But most of the loans lost seem to be mid-range in risk.

Another dimension we haven't looked at yet is the actual loss vs. the estimated loss. Let's check that out
```{r}
ggplot(data=subset(prosper, (LP_NetPrincipalLoss > 0)), aes(x=EstimatedLoss, y=LP_NetPrincipalLoss/LoanOriginalAmount)) + geom_point(alpha=0.5, position="jitter") +
  xlab("Estimated Loss Rate") +
  ylab("Actual Principal Loss Rate")
```
There's effectively no correlation. cor.test will confirm
```{r}
with(subset(prosper, (LP_NetPrincipalLoss > 0)), cor.test(EstimatedLoss, LP_NetPrincipalLoss/LoanOriginalAmount))
with(prosper, cor.test(EstimatedLoss, LP_NetPrincipalLoss/LoanOriginalAmount))
```
0.08453763 is basically nothing when only considering loans that have had losses. 0.2102577 with all loans, though still not well correlated when the data is plotted.


Let's take these questions in a different direction and think from the point of view of the vendor. Let's first ask, how much have lenders made on loans given? Is there some correlation with loan term? How about over time?
```{r}
ggplot(data=prosper, aes(x=LenderYield)) + geom_histogram() +
  xlab("Lender Yield Rate")

ggplot(data=prosper, aes(x=LenderYield)) + 
  geom_histogram(aes(fill=factor(Term))) +
  xlab("Lender Yield Rate") +
  scale_y_sqrt()

ggplot(data=prosper, aes(x=LoanOriginationDate_decimal, y=LenderYield)) +
  geom_point(alpha=0.2) +
  xlab("Loan Origination Date") +
  ylab("Lender Yield Rate") +
  scale_x_continuous(breaks=seq(2005, 2014, 1))
```
What this tells me is that no matter what, lenders have almost always made money on a loan. It's also effectively telling me that the loan yield rate doesn't depend much on time. Additionally, while the vast majority of loans are for 36 months, terms don't seem to matter as much in whether or not there will be appreciable yield (although short term loans have a yield cap below 0.3). Interesting how lending effectively came to a stop between the end of 2008 and mid 2009. The financial crisis really shut things down.

I'm curious about these parameters involving "investments made by friends". Let's do histograms and time-series stuff.
```{r}
plt1 = ggplot(data=prosper, aes(x=InvestmentFromFriendsCount)) + 
  geom_histogram() +
  xlab("Number of Friends Investing")
plt2 = ggplot(data=prosper, aes(x=InvestmentFromFriendsAmount)) + 
  geom_histogram() +
  xlab("Amount Friends have Invested ($)")
plt3 = ggplot(data=prosper, aes(x=Investors)) + 
  geom_histogram() +
  xlab("Number of Investors Funding the Loan")

grid.arrange(plt1, plt2, plt3, ncol=1)
```
Largely fruitless. Except for that last one. Let's look at that in some greater detail.

```{r}
bw = 25
ggplot(data=prosper, aes(x=Investors)) + 
  geom_histogram(binwidth=bw, origin=-bw/2) +
  xlab("Number of Investors Funding the Loan") +
  scale_y_log10()
```
Hmm. I have an idea of how this plays out with respect to loan amount but I want to see it for myself. 

First, I need to bin up some data.
```{r}
prosper$LoanOriginalAmount.buckets <- cut(prosper$LoanOriginalAmount, 
                                          quantile(prosper$LoanOriginalAmount,
                                                   probs=c(0, .2, .4, .6, .8, 1.)))
```
Now revisit those investors
```{r}
bw = 25
ggplot(data=prosper, aes(x=Investors)) + 
  geom_histogram(aes(fill=LoanOriginalAmount.buckets)) +
  xlab("Number of Investors Funding the Loan") +
  scale_x_sqrt(breaks=c(15, 170, 500, 1000))
```

I don't really...see this one going anywhere. I've stepped through a number of interesting variables though. Let's plot N things vs N things, then start up on the final report.
```{r}
interesting_columns <- c(4,8,10,16,17,20,22,23,24,26,27,37,47,50,75,78)
ggpairs(prosper, columns=interesting_columns, axisLabels="internal")
```
Not much of interest here. 

Let's check on one more thing that just came to mind: Debt/Income ratio vs avg credit rating, colored by loan amount
```{r}
bw = 20
plt1 = ggplot(data=subset(prosper, !is.na(DebtToIncomeRatio) & !is.na(CreditScoreRangeUpper) & !is.na(CreditScoreRangeLower) & (CreditScoreRangeLower > 0) & (CreditScoreRangeUpper > 0)), 
       aes(x=round((CreditScoreRangeUpper + CreditScoreRangeLower)/2 / bw) * bw, y=DebtToIncomeRatio)) +
  geom_point(position="jitter", alpha=0.2, aes(color=LoanOriginalAmount.buckets)) +
  geom_line(stat="summary", color="green", fun.y=mean)

plt2 = ggplot(data=subset(prosper, !is.na(DebtToIncomeRatio) & !is.na(CreditScoreRangeUpper) & !is.na(CreditScoreRangeLower) & (CreditScoreRangeLower > 0) & (CreditScoreRangeUpper > 0) & (DebtToIncomeRatio < 1.25)), 
       aes(x=round((CreditScoreRangeUpper + CreditScoreRangeLower)/2 / bw) * bw, y=DebtToIncomeRatio)) +
  geom_point(position="jitter", alpha=0.2, aes(color=LoanOriginalAmount.buckets)) +
  geom_line(stat="summary", color="green", fun.y=mean)

grid.arrange(plt1, plt2, ncol=1)
```
Not entirely surprising but still interesting to see, the highest loans are given to people with better credit scores, while lower loans are available for most folks. What was more interesting to see was that the $5,000 - $15,000 range of loans was available all the way down to a credit score of 600. That's a lot lower than I had expected, so I've learned something there. Also interesting to see the few cases where high debt/income ratios were still given loans. They were few and far between. Note that any debt/income ratio larger than 10 is shown as 10.01. So the structure for really high debt/income ratios is pretty much lost. 

I'm curious about the breakdown by the original loan amount buckets, so let's do that plot and then move on.
```{r}
ggplot(data=subset(prosper, !is.na(DebtToIncomeRatio) & !is.na(CreditScoreRangeUpper) & !is.na(CreditScoreRangeLower) & (CreditScoreRangeLower > 0) & (CreditScoreRangeUpper > 0) & (DebtToIncomeRatio < 1.25)), 
       aes(x=round((CreditScoreRangeUpper + CreditScoreRangeLower)/2 / bw) * bw, y=DebtToIncomeRatio)) +
  geom_point(position="jitter", alpha=0.2) +
  geom_line(stat="summary", color="green", fun.y=mean) +
  facet_wrap(~LoanOriginalAmount.buckets)
```
Apparently, keeping your debt-to-income ratio beneath 0.4 and a credit score > 620 is a great way to qualify for a loan of any type.

Let's make the credit score a little easier to work with by putting that average into our dataframe
```{r}
prosper$CreditScoreMean = (prosper$CreditScoreRangeUpper + prosper$CreditScoreRangeLower)/2
```


## Predicting Goodness of Borrower
I want to try to assess the goodness of a borrower with respect to the requested loan amount. I'll parameterize a good borrower by the net principal loss (LP_NetPrincipalLoss). Obviously, I'd want to only look at loans that have been closed, so only where ClosedDate_decimal is not NA. Here are some parameters that I think will be important to my model:
- LoanOriginalAmount: The loan's original amount
- CreditScoreMean: The average between the lower and upper range of credit score
- EmploymentStatusDuration: The length in months of the employment status of the borrower when the listing was created
- IsBorrowerHomeowner: Boolean for whether or not the borrower is a homeowner
- OpenCreditLines: Number of open credit lines at the time the credit profile was pulled
- InquiriesLast6Months: Number of inquiries in the past six months at the time the credit profile was pulled
- CurrentDelinquencies: Number of accounts delinquent at the time the credit profile was pulled
- AmountDelinquent: Dollars delinquent at the time the credit profile was pulled
- AvailableBankcardCredit: The total available credit via bank card at the time the credit profile was pulled
- StatedMonthlyIncome: The monthly income the borrower stated at the time the listing was created
- DebtToIncomeRatio: The debt to income ratio of the borrower 
```{r}
prosper_clean <- subset(prosper, (CreditScoreMean > 250) & (LP_NetPrincipalLoss > 0) &
                          !is.na(LP_NetPrincipalLoss) & !is.na(CreditScoreMean) &
                          !is.na(EmploymentStatusDuration) & !is.na(OpenCreditLines) &
                          !is.na(InquiriesLast6Months) & !is.na(AmountDelinquent) &
                          !is.na(AvailableBankcardCredit) & !is.na(DebtToIncomeRatio) &
                          !is.na(ClosedDate_decimal))

n_entries <- length(prosper_clean$Term)
all_indices <- seq(1:n_entries)

set.seed(42)
rand_samp <- sample(1:n_entries, as.integer(0.75 * n_entries)) #replace = False

prosper_train <- prosper_clean[rand_samp, ]
prosper_test <- prosper_clean[!(all_indices %in% rand_samp), ]

m1 <- lm(I(LP_NetPrincipalLoss) ~ I(CreditScoreMean), 
         data=prosper_train)
m2 <- update(m1, ~ . + LoanOriginalAmount)
m3 <- update(m2, ~ . + EmploymentStatusDuration)
m4 <- update(m3, ~ . + IsBorrowerHomeowner)
m5 <- update(m4, ~ . + OpenCreditLines)
m6 <- update(m5, ~ . + InquiriesLast6Months)
m7 <- update(m6, ~ . + CurrentDelinquencies)
m8 <- update(m7, ~ . + AmountDelinquent)
m9 <- update(m8, ~ . + AvailableBankcardCredit)
m10 <- update(m9, ~ . + StatedMonthlyIncome)
m11 <- update(m10, ~ . + DebtToIncomeRatio)

mtable(m11)
```
First thing to note is that the $R^2$ coefficient isn't very high (0.196). I've learned from [https://cran.r-project.org/web/packages/texreg/vignettes/v55i08.pdf](https://cran.r-project.org/web/packages/texreg/vignettes/v55i08.pdf) that mtable throws asterisks onto coefficients of significance, with the number of asterisks corresponding to the significance level of that coefficient. 

Perhaps we can refine our model. Let's first take out the following coefficients that appear to matter least: *CreditScoreMean, EmploymentStatusDuration, AmountDelinquent, CurrentDelinquencies, OpenCreditLines, StatedMonthlyIncome, AvailableBankcardCredit*. 
```{r}
m1 <- lm(I(LP_NetPrincipalLoss) ~ I(LoanOriginalAmount), 
         data=prosper_train)
m2 <- update(m1, ~ . + LoanOriginalAmount)
m3 <- update(m2, ~ . + IsBorrowerHomeowner)
m4 <- update(m3, ~ . + InquiriesLast6Months)
m5 <- update(m4, ~ . + DebtToIncomeRatio)

mtable(m5)
```
Now we get an $R^2$ of 20.3. Better than before, but not by much. Let's test this out on our test set, find the residuals, and plot up some stuff.
```{r}
estimated_losses <- predict(m5, newdata = prosper_test, interval="prediction",
                           level = 0.95)
prosper_test$residual_loss <- estimated_losses[, 1] - prosper_test$LP_NetPrincipalLoss

plt1 <- ggplot(data=prosper_test, 
               aes(x=DebtToIncomeRatio, y=residual_loss / LP_NetPrincipalLoss)) + 
  geom_point(aes(color = LoanOriginalAmount.buckets), alpha=0.2) + 
  xlim(0, 1.5) +
  ylim(-1.0, 10)
plt2 <- ggplot(data=prosper_test, 
               aes(x=DebtToIncomeRatio, y=LP_NetPrincipalLoss)) + 
  geom_point() +   xlim(0, 1.5) 
grid.arrange(plt1, plt2, ncol=1)
```
While it looks like I'm over-estimating a ton of entries, I think I might actually be underestimating a bunch and just not realize it. 
```{r}
summary(prosper_test$residual_loss/prosper_test$LP_NetPrincipalLoss)
```
On average I'm overestimating loss from a given borrower, though my median is saying I'm pretty close with my estimations. That mean is definitely affected by the few outliers, as it exists well outside of my 3rd quartile.

Let's histogram it up.
```{r}
ggplot(data=prosper_test, aes(x=residual_loss/LP_NetPrincipalLoss)) + 
  geom_histogram(binwidth=0.1) +
  xlim(-1, 10) +
  facet_wrap(~ LoanOriginalAmount.buckets)
```
Last bits for this model. With my random seed set to 42 (the answer to the question of the meaning of life, the universe, and everything), I get the following coefficients:
(Intercept)                          18.118     
                                    (39.817)    
I(LoanOriginalAmount)                 0.731***  
                                     (0.004)    
IsBorrowerHomeowner: True/False    -128.066**   
                                    (43.727)    
InquiriesLast6Months                 11.915*    
                                     (5.740)    
DebtToIncomeRatio                   -58.216**   
                                    (22.527)    

I want to check that these are consistent regardless of my random seed, so let's do it again!
```{r}
set.seed(79)
rand_samp <- sample(1:n_entries, as.integer(0.75 * n_entries)) #replace = False

prosper_train <- prosper_clean[rand_samp, ]
prosper_test <- prosper_clean[!(all_indices %in% rand_samp), ]

m1 <- lm(I(LP_NetPrincipalLoss) ~ I(LoanOriginalAmount), 
         data=prosper_train)
m2 <- update(m1, ~ . + LoanOriginalAmount)
m3 <- update(m2, ~ . + IsBorrowerHomeowner)
m4 <- update(m3, ~ . + InquiriesLast6Months)
m5 <- update(m4, ~ . + DebtToIncomeRatio)

mtable(m5)
```
(Intercept)                          23.605     
                                    (40.185)    
I(LoanOriginalAmount)                 0.727***  
                                     (0.004)    
IsBorrowerHomeowner: True/False    -131.634**   
                                    (44.084)    
InquiriesLast6Months                 12.605*    
                                     (5.762)    
DebtToIncomeRatio                   -43.710*    
                                    (22.263)
                                    
Not bad! Not bad at all! Now, how do I interpret this in the context of the original idea of a borrower's goodness?
- The higher the loan amount, the more the bank should expect to lose on it. The more a borrower asks for, the higher the risk.
- Owning a home correlates with less money lost on a loan. One can find good buyers amongst homeowners.
- The more inquiries that have been made into a borrower's credit history, the higher the risk.
- The higher the debt-to-income ratio, the less a bank should expect to lose. This is surprising to say the least. I'd expect higher debt-to-income ratios to correlate with more money lost per loan, but this imperfect linear model says otherwise.


##Univariate Analysis
###What is the structure of your dataset?
The prosper data set contains 113,937 loans, each with 81 characteristics. Most characteristics are continuous, though a few are qualitative attributes:
- **CreditGrade:** AA (best), A, B, C, D, E (worst), HR (high risk), NC (no credit)
- **Term:** 12, 36, 60
- **LoanStatus:** Completed, Current, Past Due (1-15 days), Defaulted, Chargedoff, Past Due (16-30 days), Cancelled, Past Due (61-90 days), Past Due (31-60 days), Past Due (91-120 days), FinalPaymentInProgress, Past Due (>120 days)
- **ProsperRating (numeric):** 0, 1, 2, 3, 4, 5, 6, 7 
- **ProsperRating (alpha):** AA, A, B, C, D, E, HR
- **ProsperScore:** 1 (worst), 2, 3, 4, 5, 6, 7, 8, 9, 10 (best)
- **ListingCategory:** 0 (N/A), 1 (Debt Consolidation), 2 (Home Improvement), 3 (Business), 4 (Personal Loan), 5 (Student Use), 6 (Auto), 7 (Other), 8 (Baby&Adoption), 9 (Boat), 10 (Cosmetic Procedure), 11 (Engagement Ring), 12 (Green Loans), 13 (Household Expenses), 14 (Large Purchases), 15 (Medical/Dental), 16 (Motorcycle), 17 (RV), 18 (Taxes), 19 (Vacation), 20 (Wedding Loans)
- **BorrowerState:** Two letter abbreviations for every state
- **Occupation:** 68 different occupations
- **EmploymentStatus:** Self-employed, Employed, Not available, Full-time, Other, Not employed, Part-time, Retired
- **IsBorrowerHomeowner:** Boolean
- **CurrentlyInGroup:** Boolean
- **IncomeVerifiable:** Boolean

#####Other Observations:
- Most loans have 3-year terms (77%), while another sizeable fraction have 5-year terms (21.5%).
- Most loans are currently in payment or completed. A significant portion however have been Charged-off (10.5%), and a smaller portion have gone into default (4.4%).
- Loans aren't given below $1,000, and the largest loan in the data set is $35,000. Most loans are smaller loans, shown by how the median ($6,500) is below the mean ($8,337).
- The state with the largest number of loans (by far) is California, with 14,717 loans. The next largest is Texas, with 6,842 loans.
- The overwhelming majority of loans (51.2%) were for debt consolidation
- The average borrower APR is 0.218
- Interestingly enough, there isn't one credit grade dominating the borrower population. The largest fraction have an average grade of about C, but there's a pretty even smattering from A through E. The biggest differences are that AA rated borrowers make up the smallest sample, while HR rated borrowers are around the same level as AA rated borrowers.
- The median debt-to-income ratio for borrowers is 0.22. The debt-to-income ratio is notably skewed to not just below 1, but well below 0.5.
- It's noted above, but there are no loans in this set from between November 2008 and April 2009. Coincident with the financial crisis, and even in April 2009 there's only a small spike in loans before going dead again for about 2 months.
- The split between borrowers that are and aren't homeowners is pretty even. Homeowners outnumber non-owners by about 1000, which isn't much considering it's a difference betwen 57,478 and 56,459.

####What is/are the main feature(s) of interest in your dataset?
The main features of the data set are LenderYield, LoanOriginalAmount, and LP_NetPrincipalLoss. Above I used other characteristics of loans to try to predict LP_NetPrincipalLoss on loans. It wasn't half bad!

####What other features in the dataset do you think will help support your investigation into your feature(s) of interest?
I'd initially thought that CreditScoreMean, EmploymentStatusDuration, IsBorrowerHomeowner, OpenCreditLines, InquiriesLast6Months, CurrentDelinquencies, AmountDelinquent, AvailableBankcardCredit, StatedMonthlyIncome, and DebtToIncomeRatio were all important when considering whether a loan would end up with a net loss, due to several facts and suggestions gleaned from investigations into personal credit. However, it ended up being that only the Loan Original Amount, the homeowner status, the last 6 months of credit inquiries, and the debt to income ratio were significant (as far as an inherently-flawed linear model was concerned).

####Did you create any new variables from existing variables in the dataset?
Quite a few actually. Any variable with date information I broke apart into columns containing the day, the month, the year, and the date as a decimal of the year using `strptime` and `strftime`.

I created a variable called LoanOriginalAmount.buckets, containing 5 ranges of dollar amounts within which a loan could reside. It was helpful for looking at some distributions with respect to the loan amount range. 

Lastly, I created a variable for the mean credit score, based on the upper and lower limits of credit scores for each borrower. Its purpose was so that I could pin down roughly which credit scores correspond to which loan/borrower characteristics, instead of having to interpret from a range.

####Of the features you investigated, were there any unusual distributions? Did you perform any operations on the data to tidy, adjust, or change the form of the data? If so, why did you do this?
The only unusual distributions that I took note of involved the debt-to-income ratios and the mean credit scores. It's noted in the variable definitions file that the debt-to-income ratio metric caps at 10.01, regardless of how high the actual ratio might be. That produced slight anomalies in my distribution, and I ended up focusing mostly on debt-to-income ratios below 1.

The mean credit scores were odd in that the distribution went down to 9.5 even though credit scores shouldn't really be below about 360. For my model analysis I ended up just using only credit scores that were above 250 and not "NA".

Additionally, specifically for my linear model, I made sure every loan considered had a principal loss > 0, had some employment status duration (since it was a part of my initial variable set), open credit lines, inquiries in the last 6 months, some delinquent amount, some bankcard credit, some debt to income ratio, and some close date (to ensure that the loan was finished and not just late in payment). Basically I wanted to make sure that every variable considered for my model had a value that could be used to train the model.

##Bivariate Analysis
####Talk about some of the relationships you observed in this part of the investigation. How did the feature(s) of interest vary with other features in the dataset?
####Did you observe any interesting relationships between the other features (not the main feature(s) of interest)?
####What was the strongest relationship you found?

##Multivariate Analysis
####Talk about some of the relationships you observed in this part of the investigation. Were there features that strengthened each other in terms of looking at your feature(s) of interest?
####Were there any interesting or surprising interactions between features?
####OPTIONAL: Did you create any models with your dataset? Discuss the strengths and limitations of your model.

##Final Plots and Summary
####Plot One
####Plot Two
####Plot Three

##Reflection
