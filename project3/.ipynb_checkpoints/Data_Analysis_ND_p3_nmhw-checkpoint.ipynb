{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Project 3: Wrangling OpenStreetMap Data\n",
    "\n",
    "<b>Author:</b> Nicholas Hunt-Walker\n",
    "\n",
    "<b>Start-date:</b> November 11, 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First data description\n",
    "<ul>\n",
    "<li><b>Location:</b> Austin, TX</li>\n",
    "<li><b>Data Retrieved:</b> November 10, 2015</li>\n",
    "<li><b>Retrieved From:</b> [MapZen](https://mapzen.com/data/metro-extracts)</li>\n",
    "<li><b>XML File Size:</b> 92.3 MB</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Traverse the XML Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "node_types = set()\n",
    "node_ids = set()\n",
    "node_count = {}\n",
    "data = []\n",
    "\n",
    "infile = \"austin_texas.osm\"\n",
    "# infile = \"auburn_alabama.osm\"\n",
    "\n",
    "CREATED = [\"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "POSITION = [\"lat\", \"lon\"]\n",
    "format_gnis = {\n",
    "    \"gnis:Class\" : \"feature_class\", \"gnis:County\" : \"county\",\n",
    "    \"gnis:County_num\" : \"county_fips_code\", \"gnis:ST_alpha\" : \"state_abbrv\",\n",
    "    \"gnis:ST_num\" : \"state_fips_code\", \"gnis:county_id\" : \"county_fips_code\",\n",
    "    \"gnis:created\" : \"entry_date\", \"gnis:state_id\" : \"state_fips_code\",\n",
    "    \"gnis:id\" : \"gnis_id\"\n",
    "}\n",
    "gnis_multiples = [\"feature_id\", \"entry_date\"]\n",
    "tiger_multiples = [\"tlid\", \"county\", \"cfcc\", \"name_base\"]\n",
    "\n",
    "format_address = {\n",
    "    \"addr:housenumber\" : \"house_number\", \"addr:housename\" : \"house_name\",\n",
    "    \"addr:street\" : \"street_address\", \"addr:postcode\" : \"post_code\",\n",
    "}\n",
    "\n",
    "street_mapping = { \n",
    "            \"St\": \"Street\", \"Ave\": \"Avenue\", \"Rd\": \"Road\", \n",
    "            # I added the following\n",
    "            \"Bld\" : \"Building\", \"Bldg\" : \"Building\", \"Blvd\" : \"Boulevard\",  \n",
    "            \"Cir\" : \"Circle\", \"Ct\" : \"Court\", \"Cv\" : \"Cove\",              \n",
    "            \"Dr\" : \"Drive\", \"Expwy\" : \"Expressway\", \"Hwy\" : \"Highway\",              \n",
    "            \"HWY\" : \"Highway\", \"Ln\" : \"Lane\", \"Pkwy\" : \"Parkway\",  \n",
    "            \"Ste\" : \"Suite\", \"STE\" : \"Suite\", \"Wy\" : \"Way\",              \n",
    "            }\n",
    "lower_these = [\"amenity\", \"cuisine\"]\n",
    "\n",
    "def clean_input(the_str, sep=None):\n",
    "    cleaned_str = the_str.replace(u\"\\u2013\", \"-\").replace(\"en:\", \"\")\n",
    "    if sep:\n",
    "        cleaned_str = cleaned_str.split(sep)\n",
    "    \n",
    "    return cleaned_str\n",
    "\n",
    "def correct_street_address(street_name):\n",
    "    for key in street_mapping.keys():\n",
    "        m = re.search(\"(\" + key + \")(?![a-z])\", street_name)\n",
    "        if m:# and (street_name.find(street_mapping[key]) == -1):\n",
    "            street_name = street_name.replace(key, street_mapping[key])\n",
    "    \n",
    "    street_name = street_name.replace(\".\",\"\").replace(\"#\",\"\")\n",
    "    return street_name          \n",
    "\n",
    "def correct_post_code(code):\n",
    "    search_str = re.compile(r'^[A-Z]+', re.IGNORECASE)\n",
    "    anomaly = re.search(search_str, code)\n",
    "    if anomaly:\n",
    "        code = code.replace(anomaly.group(), \"\").strip().split(u\"\\u2013\")[0][:5]\n",
    "    else:\n",
    "        return code[:5]\n",
    "    \n",
    "    if code == \"\":\n",
    "        return \"Invalid\"\n",
    "    else:\n",
    "        return code[:5]\n",
    "\n",
    "for _, element in ET.iterparse(infile):\n",
    "    the_tag = element.tag\n",
    "    \n",
    "    if the_tag in node_types:\n",
    "        node_count[the_tag] += 1\n",
    "    else:\n",
    "        node_types.add(the_tag)\n",
    "        node_count[the_tag] = 1\n",
    "\n",
    "    if (the_tag == \"way\") or (the_tag == \"node\"):\n",
    "        new_node_way = {\"type\":the_tag,\n",
    "                        \"created\":{}}\n",
    "\n",
    "        for key in element.attrib.keys():\n",
    "            if key in CREATED:\n",
    "                new_node_way[\"created\"][key] = element.attrib[key]\n",
    "            elif key not in POSITION:\n",
    "                new_node_way[key] = element.attrib[key]\n",
    "                \n",
    "        if the_tag == \"node\":\n",
    "            new_node_way[\"position\"] = []\n",
    "            if len(new_node_way[\"position\"]) < 2:\n",
    "                new_node_way[\"position\"].append(float(element.attrib[\"lat\"]))\n",
    "                new_node_way[\"position\"].append(float(element.attrib[\"lon\"]))\n",
    "\n",
    "        if the_tag == \"way\":\n",
    "            if \"nd\" in [em.tag for em in element.getchildren()]:\n",
    "                new_node_way[\"node_refs\"] = []\n",
    "                for tag in element.iter(\"nd\"):\n",
    "                    new_node_way[\"node_refs\"].append(tag.attrib[\"ref\"])\n",
    "\n",
    "        if \"tag\" in [em.tag for em in element.getchildren()]:\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if tag.attrib[\"k\"].startswith(\"tiger\"):\n",
    "                    if \"tiger_tags\" not in new_node_way.keys():\n",
    "                        new_node_way[\"tiger_tags\"] = {}\n",
    "                        \n",
    "                    new_key = tag.attrib[\"k\"].split(\":\")[1]\n",
    "                    if new_key in tiger_multiples:\n",
    "                        new_input = clean_input(tag.attrib[\"v\"], sep=\":\")\n",
    "                    else:\n",
    "                        new_input = clean_input(tag.attrib[\"v\"])\n",
    "                    new_node_way[\"tiger_tags\"][new_key] = new_input\n",
    "                    \n",
    "                elif tag.attrib[\"k\"].startswith(\"addr\"):\n",
    "                    if \"address\" not in new_node_way.keys():\n",
    "                        new_node_way[\"address\"] = {}\n",
    "                    \n",
    "                    if tag.attrib[\"k\"] in format_address.keys():\n",
    "                        new_key = format_address[tag.attrib[\"k\"]]\n",
    "                        \n",
    "                    elif tag.attrib[\"k\"].split(\":\")[1] != \"state\":\n",
    "                        new_key = tag.attrib[\"k\"].split(\":\")[1]\n",
    "                        \n",
    "                    new_input = clean_input(tag.attrib[\"v\"])\n",
    "                    if new_key == \"city\":\n",
    "                        new_input = new_input.split(',')[0]\n",
    "                        if new_input.lower() == \"tx\" or new_input.lower() == \"texas\":\n",
    "                            new_input = \"Austin\"\n",
    "                        \n",
    "                    if new_key == \"street_address\":\n",
    "                        new_input = correct_street_address(new_input)\n",
    "#                         street_addresses.add(new_input)\n",
    "                        \n",
    "                    if new_key == \"post_code\":\n",
    "                        new_input = correct_post_code(new_input)\n",
    "                        \n",
    "                    new_node_way[\"address\"][new_key] = new_input\n",
    "                    \n",
    "                elif tag.attrib[\"k\"].startswith(\"gnis\"):\n",
    "                    if \"gnis\" not in new_node_way.keys():\n",
    "                        new_node_way[\"gnis\"] = {}\n",
    "                        \n",
    "                    if tag.attrib[\"k\"] in format_gnis.keys():\n",
    "                        new_key = format_gnis[tag.attrib[\"k\"]]\n",
    "                    else:\n",
    "                        new_key = tag.attrib[\"k\"].split(\":\")[1]\n",
    "                        \n",
    "                    if new_key in gnis_multiples:\n",
    "                        new_input = clean_input(tag.attrib[\"v\"], sep=\";\")\n",
    "                    else:\n",
    "                        new_input = clean_input(tag.attrib[\"v\"])\n",
    "                    new_node_way[\"gnis\"][new_key] = new_input\n",
    "                    \n",
    "                else:\n",
    "                    new_input = clean_input(tag.attrib[\"v\"])\n",
    "                    if tag.attrib[\"k\"] == \"maxspeed\":\n",
    "                        if new_input.endswith(\"mph\"):\n",
    "                            new_input = new_input.replace(\"mph\", \" mph\").replace(\"  \", \" \")\n",
    "                            \n",
    "                        else:\n",
    "                            new_input = new_input + \" mph\"\n",
    "                    if tag.attrib[\"k\"] in lower_these:\n",
    "                        new_node_way[tag.attrib[\"k\"]] = new_input.lower()\n",
    "                    else:\n",
    "                        new_node_way[tag.attrib[\"k\"]] = new_input\n",
    "\n",
    "        data.append(new_node_way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounds': 1,\n",
       " 'member': 13537,\n",
       " 'nd': 951652,\n",
       " 'node': 822765,\n",
       " 'osm': 1,\n",
       " 'relation': 1315,\n",
       " 'tag': 549875,\n",
       " 'way': 85505}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The total numbers for each type of tag in the XML file\n",
    "node_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Insert the Resulting JSON into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client.examples\n",
    "db.drop_collection(\"city_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ii in range(len(data)):\n",
    "    db.city_data.insert(data[ii])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreted from [ScribeKey](http://www.scribekey.com/EntityAttributes/EDGES.html), and the [OSM wiki](http://wiki.openstreetmap.org/wiki/TIGER_to_OSM_Attribute_Map), these are explanations of the TIGER keys:\n",
    "<ul>\n",
    "<li><b>zip\\_right/left: </b>ZIP code associated with the most inclusive address range on the right/left side</li>\n",
    "<li><b>tiger:cfcc: </b>Census Feature Class Code. Describes the primary feature type for a linear feature. These codes are defined here [link](http://support.esri.com/fr/knowledgebase/techarticles/detail/11966). Note that these codes were replaced by the MAF/TIGER Feature Class Code MTFCC in 2007. Those class codes are defined here: [link](https://www.census.gov/geo/reference/mtfcc.html).</li>\n",
    "<li><b>tiger:name\\_direction\\_prefix\\_%n: </b>The prefix for the street name, e.g. \"NW\", or \"SE\".</li>\n",
    "<li><b>tiger:name\\_base\\_%n: </b>The street's name alone. The regular <b>name\\_base</b> is the primary name, and every other one after that is an alias</li>\n",
    "<li><b>tiger:name\\_type\\_%n: </b>Like a \"Rd\", \"Ave\", \"St\", etc. </li>\n",
    "<li><b>tiger:name\\_direction\\_suffix\\_%n: </b>The suffix for the street name, e.g. \"S\", or \"N\"</li>\n",
    "<li><b>name\\_%n: </b>The full street name. It's a combination of \"name_direction_prefix\" + \"name_base\" + \"name_type\" + \"name_direction_suffix\"</li>\n",
    "<li><b>reviewed</b> Set to \"no\" for ALL ways. It doesn't seem to be an accurate indication of anything in particular.</li>\n",
    "</ul>\n",
    "\n",
    "Map features are specifically described [here](http://wiki.openstreetmap.org/wiki/Map_Features)\n",
    "\n",
    "Nodes have a different set of keys, not taken from TIGER it seems. They're taken from GNIS, along with some other descriptors.\n",
    "<ul>\n",
    "<li><b>GNIS tags described: </b> [here](http://wiki.openstreetmap.org/wiki/USGS_GNIS)</li>\n",
    "<li><b>gnis:ST_num: </b>State FIPS code</li>\n",
    "<li><b>gnis:ST_alpha: </b>State name (2-Letter abbreviation)</li>\n",
    "<li><b>gnis:County_num: </b>County FIPS code</li>\n",
    "<li><b>gnis:Class: </b>Feature Class name. The meaning of the feature classes are found [here](http://wiki.openstreetmap.org/wiki/USGS_GNIS)</li>\n",
    "<li><b>gnis:County: </b>County name</li>\n",
    "<li><b>gnis:id: </b></li>\n",
    "<li><b>ele: </b>GNIS data includes elevation</li>\n",
    "<li><b>place: </b>described [here](http://wiki.openstreetmap.org/wiki/Key:place)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra help:\n",
    "- http://stackoverflow.com/questions/13093727/how-to-replace-unicode-characters-in-string-with-something-else-python\n",
    "- http://regexr.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing issues with the data set:\n",
    "- Some items with GNIS data had multiple feature_id's and entry dates, separated by semicolons. Those were captured, split by the semicolon, and put into the database as arrays.\n",
    "- In the same vein, a few tags from TIGER also had multiple values, though these were separated by colons. Those were also captured and put into arrays.\n",
    "- Postal codes could have a variety of configurations. I noted this specifically by testing for distinct postal codes with a set() on one of the preliminary runs of the data. Most are 5-digit format but some have A-Z characters, some have more than 5 digits, and some are entirely invalid. I used a regex string to search for any A-Z characters and remove them. If there was nothing left, I returned \"Invalid\". Otherwise, I took the first 5 numbers as the postal code.\n",
    "- For the street addresses, I took a page out of Lesson 6 and used regex strings to search for replaceable street abbreviations. This one was particularly difficult, as sometimes an abbreviated street name could also serve as part of a word. For example \"St\" could be \"street\" or the start of \"Star Avenue\". Trying a simple \"replace\" function would turn such an address into \"Streetar Avenue\", so I had to search for abbreviations that were not followed by any alphabet character.\n",
    "- I decided not to format the directional letters (S, N, NE, SE, SW, etc.) in the street addresses. I realized that while I could reliably replace those letter selections, I might also be wrecking the address for, say, 221 Avenue N\n",
    "- Some addresses had inputs for City that were \"Tx, \"TX\", \"tx\", or \"Texas\". I just changed all those presenting any variation of \"texas\" to \"Austin\"\n",
    "- Speed limits weren't uniform so I made sure they all had \"mph\" at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##Step 3: Get Stats from the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of entries: 908270\n",
      "The total number of nodes: 822760\n",
      "The total number of ways: 85497\n"
     ]
    }
   ],
   "source": [
    "print \"The total number of entries: {0}\".format(db.city_data.find().count())\n",
    "print \"The total number of nodes: {0}\".format(db.city_data.find({\"type\" : \"node\"}).count())\n",
    "print \"The total number of ways: {0}\".format(db.city_data.find({\"type\" : \"way\"}).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "number_of_unique_users = db.city_data.aggregate([\n",
    "                                          {\"$group\" : {\n",
    "                                             \"_id\" : \"$created.user\",\n",
    "                                             \"count\" : {\"$sum\" : 1}\n",
    "                                                      }\n",
    "                                          }])\n",
    "top_5_users = db.city_data.aggregate([\n",
    "                                      {\"$group\" : {\n",
    "                                            \"_id\" : \"$created.user\",\n",
    "                                            \"count\" : {\"$sum\" : 1}\n",
    "                                      }},\n",
    "                                      {\"$sort\" : {\"count\" : -1}},\n",
    "                                      {\"$limit\" : 5 }\n",
    "                                     ])\n",
    "five_most_popular_amenities = db.city_data.aggregate([{\"$match\" : {\"amenity\" : {\"$exists\" : 1}}},\n",
    "                                                      {\"$group\" : {\"_id\" : \"$amenity\",\n",
    "                                                                  \"count\" : {\"$sum\" : 1}}\n",
    "                                                      },\n",
    "                                                      {\"$sort\" : {\"count\" : -1}},\n",
    "                                                      {\"$limit\" : 5}\n",
    "                                                     ])\n",
    "\n",
    "\n",
    "distinct_amenities = db.city_data.distinct(\"amenity\")\n",
    "number_of_amenities = len(distinct_amenities)\n",
    "number_of_schools = int(db.city_data.find({\"amenity\" : \"school\"}).count())\n",
    "number_of_cafes = int(db.city_data.find({\"amenity\" : \"cafe\"}).count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021\n"
     ]
    }
   ],
   "source": [
    "user_count = 0\n",
    "for doc in number_of_unique_users: user_count += 1\n",
    "print user_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The five most popular amenities in Austin, TX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 1910, u'_id': u'parking'}\n",
      "{u'count': 711, u'_id': u'restaurant'}\n",
      "{u'count': 591, u'_id': u'waste_basket'}\n",
      "{u'count': 565, u'_id': u'school'}\n",
      "{u'count': 532, u'_id': u'fast_food'}\n"
     ]
    }
   ],
   "source": [
    "for doc in five_most_popular_amenities: print doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 contributing users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 234473, u'_id': u'woodpeck_fixbot'}\n",
      "{u'count': 37679, u'_id': u'varmint'}\n",
      "{u'count': 36494, u'_id': u'richlv'}\n",
      "{u'count': 35579, u'_id': u'Clorox'}\n",
      "{u'count': 35207, u'_id': u'Iowa Kid'}\n"
     ]
    }
   ],
   "source": [
    "for doc in top_5_users: print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of schools: 565\n",
      "The number of cafes: 130\n",
      "The number of distinct amenities: 84\n"
     ]
    }
   ],
   "source": [
    "print \"The total number of schools: {0}\".format(number_of_schools)\n",
    "print \"The number of cafes: {0}\".format(number_of_cafes)\n",
    "print \"The number of distinct amenities: {0}\".format(len(distinct_amenities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# amenities_counts = db.city_data.aggregate([{\"$match\" : {\"amenity\" : {\"$exists\" : 1}}},\n",
    "#                                                       {\"$group\" : {\"_id\" : \"$amenity\",\n",
    "#                                                                   \"count\" : {\"$sum\" : 1}}\n",
    "#                                                       },\n",
    "#                                                       {\"$sort\" : {\"count\" : -1}}\n",
    "#                                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for doc in amenities_counts:\n",
    "#     print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buildings = db.city_data.find({\"type\":\"node\", \"building\":{\"$exists\":1}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 4: Speculate on Data Uses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Amenity/Cuisine Densities</b>\n",
    "\n",
    "The positions that are saved for each \"node\" document can be used to look at not only how popular a given amenity/cuisine type is, but how densely populated certain areas of the city are by those amenities. With that type of information I could compare two cities and look at a potential proxy for obesity by looking at the densities of fast food establishments between the two cities.\n",
    "\n",
    "Another comparative analysis would involve the densities of police stations, hospitals, pharmacies, fire houses, and clinics per capita. Comparing those densities to somewhere like Auburn, Alabama or Seattle, WA could tell me how relatively well-equipped the cities are for emergencies.\n",
    "\n",
    "<b>Accessibility/Traffic Flow</b>\n",
    "\n",
    "By using the speed limit data from the \"way\" documents, iwe should be able to assess the objectively fastest route between two points, given no traffic and no traffic-regulation devices. Unfortunately, the data from Austin, TX doesn't include information about traffic signals on the roadways (lights or signs), so we couldn't use this data to find the true fastest route. But, to put more realism toward the project, we could use data from the U.S. Census to estimate the working population, the fraction of that population that uses a private vehicle to travel, the fraction that use public transport to travel, speed limit infoormation, and the assumption that no people (or some small fraction of people) live near working centers in order to estimate what traffic flow should be like for given hours of the day. It would no doubt be a crude estimation though.\n",
    "\n",
    "<b>Enhancing a Real Estate App</b>\n",
    "\n",
    "When looking for a new place to live (or reasons to mark up your place when trying to sell), a good thing to know would be a location's proximity to things people might want. We could use this data set to say for a given house location:\n",
    "- How close is the nearest amenity?\n",
    "- Within a given radius of miles/km, how many amenities are there? Of specific types?\n",
    "- How close is the nearest highway? Highway onramp/offramp?\n",
    "- What types of food are available within a given radius?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've been able to clean the data from the OpenStreetMaps pull for Austin, TX. It's not absolutely perfect (street names for example), but it's pretty well standardized and ready for use in whatever comes next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing the sample file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Taken from the instructor notes\n",
    "outfile = \"austin_sample.osm\"\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(outfile, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every 20th top level element\n",
    "    for i, element in enumerate(get_element(infile)):\n",
    "        if i % 20 == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
